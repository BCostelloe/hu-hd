{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e259656-d3a2-4c1a-9d1a-ced38cc76368",
   "metadata": {},
   "source": [
    "This code chooses random frames from each track in a given video and creates a 5-second video of that tracked individual starting at that frame. It saves the video using a filename that encodes the observation, individual and starting frame number. These videos will then be classified as either stationary, walking or running.\n",
    "\n",
    "Note that throughout this notebook, the frame numbers are in relation to the first frame of the observation (when the drone is in position above the animals), NOT in relation to the first frame of the raw drone video (which can begin before the drone takes off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fbfd70-b208-4306-ba57-355234c9c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "import cv2\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mount = '/home/blair/server/herd_hover'\n",
    "main_folder = os.path.join(mount, 'processing','kenya-tracking', 'processed-videos', 'raw-footage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82fa58a-7fa4-448a-9653-268f32b13ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set observation number and read in 2-sec subsetted tracks file\n",
    "t = '027'\n",
    "file = 'tracks-for-segmentation/ob' + t + '_sub2sec.csv'\n",
    "tracks = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38eb07f-1ab2-4664-8240-7d99a0897d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f47bb753294c9e99b4ee46b47a69b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick random frames from each track. The number of random frames is the number of subsetted frames divided by 10 with a max of 30\n",
    "rand_frames = {}\n",
    "for i in tqdm(np.unique(tracks['trackID'])):\n",
    "    allframes = tracks[tracks['trackID'] == i]['time'].values\n",
    "    n_frames = int(round(len(allframes)/10,0))\n",
    "    if n_frames > 30: # maximum of 30 videos for each track\n",
    "        n_frames = 30\n",
    "    picks = np.random.choice(allframes, n_frames, replace = False)\n",
    "    rand_frames[i] = picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2b3ca6-ce7d-4c6a-8dae-e07f35f4071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b338ecccef2404e850c374c5be55752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5610b701c594f3eb2a91f8b49c5cc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ebc5e385894584b721f11098335bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487dafc6f9954b3cac6d60c367ed6e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4d60a73e714e3d8b0d498df97542b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81fa5b0a4d24d45bb3c80e4ddf4fe86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8d211e6d89444fb31f1e6fb1247f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da3ca991e1343fa855ecfeeff4a0c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each random frame, copy it and the next 150 frames into an individual folder on the server\n",
    "for i in tqdm(rand_frames):\n",
    "    # get observation and track numbers\n",
    "    ob = 'observation' + i.split('b')[1].split('-')[0]\n",
    "    #ob_num = i.split(\n",
    "    track = i.split('0')[-1:]\n",
    "    if len(track[0]) == 0:\n",
    "        track = ['0']\n",
    "    track_num = 'track-' + track[0]\n",
    "    # set folder containing individual images \n",
    "    crop_folder = os.path.join(main_folder, ob, 'individual_images', track_num)\n",
    "    # # get and sort list of all images in the crop folder and sub-folders\n",
    "    # jpg_list = glob.glob(crop_folder+'/**/*.jpg', recursive = True)\n",
    "    # jpg_list.sort()\n",
    "   \n",
    "    # take the first random frame and copy it along with the next 150 frames into a folder\n",
    "    for p in tqdm(rand_frames[i]):\n",
    "         # create a folder to hold frames for the video\n",
    "        new_folder = os.path.join('groundtruth-clips', ob, track_num, str('startframe_' + str(p).zfill(5)))\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        for t in np.arange(p, p+150):\n",
    "            frame = 'frame_' + track[0].zfill(2) + '_' + str(t).zfill(5) + '.jpg'\n",
    "            pattern = crop_folder + '/**/' + frame\n",
    "            for fname in glob.glob(pattern, recursive=True):\n",
    "                shutil.copy(fname, os.path.join(new_folder, frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf2c77-4222-464e-b0b6-f142a8c6e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each folder created in previous step, go through and combine frames into a video. Work in random order within a given track.\n",
    "\n",
    "# First need to check that there are 150 frames in the folder (may not be the case for clips starting near the end of the ob).\n",
    "# Delete any folders with fewer than 150 frames\n",
    "\n",
    "# Need to check that clips don't overlap other clips for that same individual. As I score videos, make a list of starting/stopping \n",
    "# frames for each video; if a new clip will overlap these ranges, stop and move to next video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a31d19-174f-494e-a662-1a1b0d80b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c0f19b8cec45c1be1a1b0711494ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_folders = glob.glob('./groundtruth-clips/*/*/*/', recursive = True)\n",
    "video_folder = os.path.join(mount, 'vigilance', 'groundtruth-clips')\n",
    "for i in tqdm(frame_folders):\n",
    "    image_folder = i\n",
    "    video_name = video_folder + '/' + ('_').join(i.split('/')[2:5]) + '.mp4'\n",
    "    if not os.path.exists(os.path.join(video_name)):\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith('.jpg')]\n",
    "        # check if there are 150 frames (if random frame was too close to end of observation, the clip may\n",
    "        # not be 5 seconds long and should be skipped.\n",
    "        if len(images) == 150:\n",
    "            images.sort()\n",
    "            frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "            height, width, layers = frame.shape\n",
    "            fps = 30\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video = cv2.VideoWriter(video_name, fourcc, fps, (width,height))\n",
    "            for image in images:\n",
    "                video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "            cv2.destroyAllWindows()\n",
    "            video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401dac0-a90e-4e85-a5d6-8e51909f1167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
