{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faee7dd",
   "metadata": {},
   "source": [
    "This notebook will read in the corrected track files, match up the tracks with their species and individual IDs, and reshape the data to work with the momentuHMM package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0875ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f427c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in csv giving the individual IDs for each track (exported from MySQL)\n",
    "track_ids = pd.read_csv('../data/trackIDs.csv')\n",
    "\n",
    "# load in csv giving the species IDs for each individual (exported from MySQL)\n",
    "track_spps = pd.read_csv('../data/trackspps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f1ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of usable observations\n",
    "# focal_obs = ['015', '027', '066', '074']\n",
    "focal_obs = ['066', '074']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in focal_obs:\n",
    "    file = '../data/raw_tracks/tracks' + t + '_final.npy'\n",
    "    tracks = np.load(file, allow_pickle = True)\n",
    "    z,f,c = tracks.shape\n",
    "    out_arr = np.column_stack((np.repeat(np.arange(z),f),tracks.reshape(z*f,-1)))\n",
    "    out_df = pd.DataFrame(out_arr, columns = ['track_num', 'lon', 'lat'])\n",
    "    out_df['frame'] = np.tile(np.arange(f),z)\n",
    "    out_df['trackID'] = ['ob' + t + '-' + str(int(p)).zfill(4) for p in out_df.track_num]\n",
    "    out_df['frame'] = np.tile(np.arange(f),z)\n",
    "    out_df['trackID'] = ['ob' + t + '-' + str(int(p)).zfill(4) for p in out_df.track_num]\n",
    "    out_df['indID'] = [track_ids[track_ids['trackID'] == p]['indID'].values[0] for p in out_df['trackID']]\n",
    "    out_df['spp'] = [track_spps[track_spps['indID'] == p]['species'].values[0] for p in out_df['indID']]\n",
    "    out_df['focal'] = [track_ids[track_ids['trackID'] == p]['focal'].values[0] for p in out_df['trackID']]\n",
    "    clean_tracks = out_df[(out_df['spp'] == 'gz') | (out_df['spp'] == 'pz')]\n",
    "    clean_tracks.dropna(inplace = True)\n",
    "    name = 'ob' + t + '_tracks.csv'\n",
    "    clean_tracks.to_csv(os.path.join('../data', 'tracks', name), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11ec2c",
   "metadata": {},
   "source": [
    "Each track file now has the coordinates for the animal's location in each frame matched up with the track ID, the individual animal ID, the species adn the focal status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa99444",
   "metadata": {},
   "source": [
    "The tracks that are output here should be the \"raw\" data that are included with the paper dataset. That is, there is no reason for readers to have to run the code in this notebook themselves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
